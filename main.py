import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns  # Grafikler iÃ§in
import string 

# NLP KÃ¼tÃ¼phaneleri
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from TurkishStemmer import TurkishStemmer

# Makine Ã–ÄŸrenmesi (Scikit-Learn)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression  # Daha kararlÄ± algoritma
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Gerekli indirmeler (Sadece ilk Ã§alÄ±ÅŸmada indirir)
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)

# 1. ADIM: VERÄ° HAZIRLIÄI VE YÃœKLEME
print("\n 1. Veri seti yÃ¼kleniyor...")

dosya_adi = 'clickbait_dataset.csv'

try:
    df = pd.read_csv(dosya_adi)
    # Etiketleri SayÄ±sal Hale Getirelim (EÄŸer metinse) veya tam tersi
    # Bizim CSV'de 1 ve 0 var. 1=Clickbait, 0=Normal
    print(f"BaÅŸarÄ±lÄ±! Toplam {len(df)} satÄ±r veri okundu.")
    
    # Veri setinde boÅŸ veri var mÄ± kontrol et ve temizle
    if df.isnull().sum().any():
        print("BoÅŸ satÄ±rlar bulundu, temizleniyor...")
        df = df.dropna()
        
except FileNotFoundError:
    print(f"HATA: '{dosya_adi}' bulunamadÄ±! LÃ¼tfen Ã¶nce veri Ã¼retici kodunu Ã§alÄ±ÅŸtÄ±rÄ±n.")
    exit()

# 2. ADIM: METÄ°N Ã–N Ä°ÅLEME FONKSÄ°YONU
print("2. Metinler temizleniyor (Stemming & Stopwords)...")

stop_words = set(stopwords.words('turkish'))
stemmer = TurkishStemmer()

def metni_temizle(metin):
    """
    Noktalama iÅŸaretlerini koruyarak temizlik yapar.
    Clickbait'ler genelde '!' ve '...' kullanÄ±r, bunlarÄ± atmamalÄ±yÄ±z.
    """
    metin = str(metin).lower()
    
    # Kelimelere ayÄ±r
    kelimeler = word_tokenize(metin)
    
    temiz_kelimeler = []
    for kelime in kelimeler:
        # Stop words temizliÄŸi yapalÄ±m ama noktalama iÅŸaretlerini KORUYALIM
        # isalpha() yerine, noktalama iÅŸaretiyse DE ekle diyoruz.
        if (kelime.isalpha() or kelime in string.punctuation) and kelime not in stop_words:
            try:
                # Sadece harf ise kÃ¶k bul, noktalama ise dokunma
                if kelime.isalpha():
                    kok = stemmer.stem(kelime)
                    temiz_kelimeler.append(kok)
                else:
                    temiz_kelimeler.append(kelime)
            except:
                temiz_kelimeler.append(kelime)
            
    return " ".join(temiz_kelimeler)

# TÃ¼m veri setine bu fonksiyonu uygula
df['islenmis_veri'] = df['baslik'].apply(metni_temizle)

# 3. ADIM: Ã–ZELLÄ°K Ã‡IKARIMI VE BÃ–LÃœMLEME
print("3. Yapay Zeka iÃ§in veriler matematiÄŸe dÃ¶kÃ¼lÃ¼yor (TF-IDF)...")

tfidf = TfidfVectorizer(ngram_range=(1, 3), min_df=1, max_features=3000, token_pattern=r'(?u)\S+')

X = tfidf.fit_transform(df['islenmis_veri']) # GiriÅŸ verisi (BaÅŸlÄ±klar)
y = df['etiket'] # Ã‡Ä±kÄ±ÅŸ verisi (0 veya 1)

# Veriyi %80 EÄŸitim, %20 Test olarak ayÄ±r
# stratify=y -> EÄŸitim ve test setinde clickbait oranÄ±nÄ± eÅŸit tutar.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# 4. ADIM: MODEL EÄÄ°TÄ°MÄ° (LOGISTIC REGRESSION)
print(" 4. Model eÄŸitiliyor...")

# Naive Bayes yerine Logistic Regression kullanÄ±yoruz.
# Ã‡Ã¼nkÃ¼ olasÄ±lÄ±k (yÃ¼zde kaÃ§ clickbait?) hesabÄ±nda daha iyidir.
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)

# BaÅŸarÄ± Skorunu Hesapla
y_pred = model.predict(X_test)
basari = accuracy_score(y_test, y_pred)

print(f"\n EÄÄ°TÄ°M TAMAMLANDI!")
print(f"Model DoÄŸruluk OranÄ±: %{basari * 100:.2f}")

# DetaylÄ± Rapor
print("\n--- DetaylÄ± SÄ±nÄ±flandÄ±rma Raporu ---")
print(classification_report(y_test, y_pred, target_names=['Normal', 'Clickbait']))

# 6. ADIM: Ä°NTERAKTÄ°F (CANLI) TEST MODU
print("\n" + "="*60)
print("SÄ°STEM HAZIR! (Ã‡Ä±kmak iÃ§in 'q' yazÄ±n)")
print("Ã–rnek: 'Åok ÅŸok ÅŸok bu kÃ¼rÃ¼ deneyen yandÄ±' veya 'YarÄ±n hava gÃ¼neÅŸli'")
print("="*60)

while True:
    giris = input("\n BaÅŸlÄ±k Girin: ")
    
    if giris.lower() in ['q', 'exit', 'Ã§Ä±k']:
        print("GÃ¼le gÃ¼le!")
        break
        
    if len(giris) < 5:
        print("LÃ¼tfen biraz daha uzun bir cÃ¼mle girin.")
        continue

    # 1. Girilen veriyi temizle
    temiz_giris = metni_temizle(giris)
    
    # 2. VektÃ¶re Ã§evir (Daha Ã¶nce eÄŸitilen tfidf'i kullan)
    vektor = tfidf.transform([temiz_giris])
    
    # 3. OlasÄ±lÄ±k Hesapla (predict_proba)
    # Model bize [Normal_OlasÄ±lÄ±ÄŸÄ±, Clickbait_OlasÄ±lÄ±ÄŸÄ±] ÅŸeklinde iki sayÄ± verir.
    olasiliklar = model.predict_proba(vektor)[0]
    clickbait_ihtimali = olasiliklar[1] # 2. sÄ±radaki deÄŸer (Clickbait olma ihtimali)
    
    # 4. Ekrana YazdÄ±r
    skor_yuzde = clickbait_ihtimali * 100
    
    print(f" Clickbait Ä°htimali: %{skor_yuzde:.1f}")
    
    if clickbait_ihtimali > 0.65:
        print("ğŸš¨ SONUÃ‡: TIK TUZAÄI (CLICKBAIT) TESPÄ°T EDÄ°LDÄ°!")
    else:
        print("âœ… SONUÃ‡: GÃœVENLÄ° (NORMAL HABER)")